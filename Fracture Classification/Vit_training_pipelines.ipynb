{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4866e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn\n",
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm, trange\n",
    "import math\n",
    "import numpy as np\n",
    "from VisionTransformer import ViTForClassfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbad305",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/MURA-v1.1/train_labels.csv')\n",
    "val_df = pd.read_csv('./data/MURA-v1.1/valid_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c81869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotation_df , config, transform=None, target_transform=None):\n",
    "        self.img_labels = annotation_df\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_labels.loc[idx, 'image_dir']\n",
    "        if config['channels'] == 1:\n",
    "            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = torch.tensor(image, dtype= torch.float32).unsqueeze(0)\n",
    "        else:\n",
    "            image = cv2.imread(img_path)\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "            image = torch.tensor(image, dtype= torch.float32)\n",
    "        label = self.img_labels.loc[idx, 'fractured']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c29f0c-1652-49d9-ba9c-4aee7e46fe25",
   "metadata": {},
   "source": [
    "# Custom VIT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac5b16-04a7-4a95-8e42-cfe7122025ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('./data/BoneFracture_localization.v2i.coco/annotation.csv')\n",
    "# Upsample fractured samples in training data\n",
    "\n",
    "# Separate fractured and unfractured samples\n",
    "fractured_df = label_df[label_df['fractured'] == 1]\n",
    "unfractured_df = label_df[label_df['fractured'] == 0]\n",
    "# unfractured_df = unfractured_df.iloc[:fractured_df.shape[0], :]\n",
    "\n",
    "# Split the fractured and unfractured data into training and validation sets\n",
    "train_frac_df, val_frac_df = train_test_split(fractured_df, test_size=0.2)\n",
    "train_unfrac_df, val_unfrac_df = train_test_split(unfractured_df, test_size=0.2)\n",
    "\n",
    "num_unfrac = len(train_unfrac_df)\n",
    "num_frac = len(train_frac_df)\n",
    "\n",
    "if num_frac < num_unfrac:\n",
    "    # Calculate how many more fractured samples are needed\n",
    "    difference = num_unfrac - num_frac\n",
    "    \n",
    "    # Upsample fractured data by duplicating random samples with replacement\n",
    "    upsampled_train_frac_df = train_frac_df.sample(difference, replace=True, random_state=42)\n",
    "    \n",
    "    # Concatenate the upsampled fractured samples with the original fractured data\n",
    "    train_frac_df = pd.concat([train_frac_df, upsampled_train_frac_df])\n",
    "\n",
    "# Concatenate upsampled fractured data with unfractured data\n",
    "train_df = pd.concat([train_frac_df, train_unfrac_df])\n",
    "\n",
    "# Concatenate validation sets without upsampling\n",
    "val_df = pd.concat([val_frac_df, val_unfrac_df])\n",
    "\n",
    "# Reset index for both train and validation dataframes\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Shuffle the training set\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_df['image_dir'] = train_df['image_dir'].apply(lambda x: './data/BoneFracture_localization.v2i.coco/train/' + x)\n",
    "val_df['image_dir'] = val_df['image_dir'].apply(lambda x: './data/BoneFracture_localization.v2i.coco/train/' + x)\n",
    "# val_df = val_df[val_df['fractured'] == 1]\n",
    "# val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf96b42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 3, 500, 500])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Configuration for the ViT model (you can adjust these as per your model design)\n",
    "config = {\n",
    "    \"encoding_size\": 256,\n",
    "    \"num_classes\": 2,\n",
    "    \"num_heads\": 4,\n",
    "    \"img_dim\": 500,\n",
    "    \"patch_size\": 20,\n",
    "    \"dropout\": 0.2,\n",
    "    'num_hidden_layers': 2,\n",
    "    'intermediate_size': 512,\n",
    "    'channels': 3,\n",
    "    'train_batch_size': 64\n",
    "}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(config['img_dim']),\n",
    "    transforms.CenterCrop(config['img_dim']),\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    transforms.RandomVerticalFlip(),\n",
    "#     transforms.RandomRotation(30),  # Randomly rotate the image\n",
    "#     transforms.ColorJitter(brightness=0.5, contrast=0.5),  # Adjust brightness and contrast\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomImageDataset(train_df, config, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['train_batch_size'], shuffle=True)\n",
    "\n",
    "val_dataset = CustomImageDataset(val_df, config, transform=transform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['train_batch_size'], shuffle=True)\n",
    "\n",
    "\n",
    "train_features, train_labels = next(iter(val_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img[0], cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62a3a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train(N_EPOCHS, criterion, optimizer, model, config):\n",
    "    # Training loop\n",
    "    for epoch in trange(N_EPOCHS, desc=\"Training\"):\n",
    "        train_loss = 0.0\n",
    "        iteration = 0  # To track the number of iterations\n",
    "        train_correct = 0\n",
    "\n",
    "        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
    "            iteration += 1\n",
    "\n",
    "            # Training Step\n",
    "            x, y = batch\n",
    "            x, y = x.cuda(), y.cuda()  # Assuming you're using a GPU\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "\n",
    "            train_loss += loss.detach().cpu().item() / len(train_dataloader)\n",
    "            _, predicted = torch.max(y_hat, 1)\n",
    "            train_correct += (predicted == y).sum().item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Validation step after every 10 iterations\n",
    "            if iteration % 10 == 0:\n",
    "                val_loss = 0.0\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                all_val_labels = []\n",
    "                all_val_probs = []\n",
    "\n",
    "                model.eval()  # Set the model to evaluation mode\n",
    "                with torch.no_grad():  # Disable gradient computation\n",
    "                    for val_batch in tqdm(val_dataloader):\n",
    "                        val_x, val_y = val_batch\n",
    "                        val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "\n",
    "                        val_y_hat = model(val_x)\n",
    "                        val_loss += criterion(val_y_hat, val_y).item() / len(val_dataloader)\n",
    "\n",
    "                        # Calculate accuracy\n",
    "                        _, predicted = torch.max(val_y_hat, 1)\n",
    "                        correct += (predicted == val_y).sum().item()\n",
    "                        total += val_y.size(0)\n",
    "\n",
    "                        # Store probabilities and labels for AUC calculation\n",
    "                        all_val_labels.extend(val_y.cpu().numpy())\n",
    "                        all_val_probs.extend(val_y_hat.softmax(dim=1)[:, 1].cpu().numpy())  # Taking probability for class 1\n",
    "\n",
    "                # Compute AUC for validation\n",
    "                val_accuracy = correct / total\n",
    "                val_auc = roc_auc_score(all_val_labels, all_val_probs)\n",
    "                \n",
    "                train_accuracy = train_correct / (iteration*config['train_batch_size'])\n",
    "#                 print(f\"Iteration {iteration}: Validation Loss: {val_loss:.2f}, Validation Accuracy: {val_accuracy:.2f}\")\n",
    "                model.train()  # Switch back to training mode\n",
    "                print(f\"Iteration {iteration}: Training Loss: {loss:.2f}, Training Accuracy: {train_accuracy:.2f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b01702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# resnet = models.resnet50(pretrained=True)\n",
    "# num_ftrs = resnet.fc.in_features\n",
    "# resnet.fc = nn.Linear(num_ftrs, 2)  \n",
    "# resnet = resnet.cuda()\n",
    "\n",
    "N_EPOCHS = 5\n",
    "\n",
    "# # Model (replace `ViTForClassification` with your actual ViT class name)\n",
    "vit = ViTForClassfication(config)\n",
    "vit = vit.cuda()  \n",
    "\n",
    "optimizer = AdamW(vit.parameters(), lr=1e-3, weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(N_EPOCHS, criterion, optimizer, vit, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151bdb5b",
   "metadata": {},
   "source": [
    "# Huggingface Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dfd0081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, Trainer, TrainingArguments, AutoFeatureExtractor\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from transformers import ViTForImageClassification, AutoImageProcessor, CvtForImageClassification\n",
    "from PIL import Image\n",
    "import torch\n",
    "from PIL import Image\n",
    "import random\n",
    "# import torchvision.transforms as T\n",
    "\n",
    "\n",
    "\n",
    "# Load the data from CSV\n",
    "data_files = {\"train\": \"./data/MURA-v1.1/train_labels.csv\",\n",
    "              \"valid\": \"./data/MURA-v1.1/valid_labels.csv\"}  # update with the correct path\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "\n",
    "# processor = AutoImageProcessor.from_pretrained(\"KhalfounMehdi/vision_transformer_mura_model_v3\")\n",
    "# model = AutoModelForImageClassification.from_pretrained(\"KhalfounMehdi/vision_transformer_mura_model_v3\")\n",
    "\n",
    "\n",
    "# model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", num_labels=2, ignore_mismatched_sizes=True)\n",
    "# processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\", num_labels=2, ignore_mismatched_sizes=True)\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-384\", num_labels=2, ignore_mismatched_sizes=True)\n",
    "model = AutoModelForImageClassification.from_pretrained(\"D3STRON/bone_fracture_vit\", num_labels=2, ignore_mismatched_sizes=True)\n",
    "\n",
    "\n",
    "# feature_extractor = AutoFeatureExtractor.from_pretrained('microsoft/cvt-21-384-22k', num_labels=2, ignore_mismatched_sizes=True)\n",
    "# model = CvtForImageClassification.from_pretrained('microsoft/cvt-21-384-22k', num_labels=2, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454ebd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples):\n",
    "    images = []\n",
    "    for image_path in examples[\"image_dir\"]:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        augmented_image = image\n",
    "        images.append(augmented_image)\n",
    "    \n",
    "    # Convert the list of images to tensors\n",
    "    inputs = processor(images=images, return_tensors=\"pt\")\n",
    "    inputs[\"labels\"] = examples[\"fractured\"]\n",
    "    return inputs\n",
    "\n",
    "# Apply the preprocessing function\n",
    "prepared_dataset = dataset[\"train\"].map(preprocess_data, batched=True, batch_size=16) \n",
    "valid_dataset = dataset[\"valid\"].map(preprocess_data, batched=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aabb2c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GHOSH\\OneDrive\\Documents\\MS\\NEU\\Assignmnets\\CS5330\\Project\\detr\\lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import evaluate\n",
    "import numpy as np\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Load the accuracy metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "#     return accuracy\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Compute basic metrics\n",
    "    precision = precision_score(labels, predictions, average=\"binary\")\n",
    "    recall = recall_score(labels, predictions, average=\"binary\")\n",
    "    f1 = f1_score(labels, predictions, average=\"binary\")\n",
    "    \n",
    "    # Compute AUC\n",
    "    if len(np.unique(labels)) == 2:  # AUC is valid only for binary classification\n",
    "        probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "        auc = roc_auc_score(labels, probabilities[:, 1])\n",
    "    else:\n",
    "        auc = None\n",
    "    \n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(labels, predictions)\n",
    "\n",
    "    # Log metrics\n",
    "    logging.info(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, AUC: {auc if auc is not None else 'N/A'}\")\n",
    "    logging.info(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    logging.info(f\"Accuracy:\\n{accuracy_metric.compute(predictions=predictions, references=labels)['accuracy']}\")\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bone_fracture_vit\",                    # Directory to save the model\n",
    "    per_device_train_batch_size=16,             # Adjust batch size as needed\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=4,                        # Number of epochs\n",
    "    save_steps=1000,                            # Save checkpoint every 500 steps\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.0002,                         # Weight decay for regularization\n",
    "    logging_strategy='steps',                  # Log at each step interval\n",
    "    report_to=\"all\",                           # Enable logging to console\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=1000,\n",
    "    warmup_ratio=0.2,                          # 10% of total steps for warmup\n",
    "    lr_scheduler_type=\"cosine\",                # Learning rate decay strategy\n",
    "    save_total_limit=1,                        # Keep only the last 2 checkpoints\n",
    "    push_to_hub=True\n",
    ")\n",
    "\n",
    "# Define the Trainer with model, arguments, and dataset\n",
    "trainer = Trainer(\n",
    "    model=model,  \n",
    "    args=training_args,\n",
    "    train_dataset=prepared_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3256c6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31792c95-7125-4995-b9e2-bb42663540c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 12:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Precision: 0.8631, Recall: 0.7379, F1: 0.7956, AUC: 0.8798777499402081\n",
      "INFO:root:Confusion Matrix:\n",
      "[[1488  179]\n",
      " [ 401 1129]]\n",
      "INFO:root:Accuracy:\n",
      "0.8185799186737567\n",
      "INFO:root:Evaluation Results: {'eval_loss': 0.45629775524139404, 'eval_model_preparation_time': 0.0033, 'eval_accuracy': 0.8185799186737567, 'eval_runtime': 779.5271, 'eval_samples_per_second': 4.101, 'eval_steps_per_second': 0.128}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Log evaluation results\n",
    "logging.info(f\"Evaluation Results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c38bb-bfb8-4236-af9c-02cb34752b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
